{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/competitive-data-science-predict-future-sales:\r\n",
      "item_categories.csv  sales_train.csv\t    shops.csv\r\n",
      "items.csv\t     sample_submission.csv  test.csv\r\n",
      "\r\n",
      "../input/pfs-dataprep:\r\n",
      "__notebook__.ipynb  __results__.html   custom.css  mean_benchmark.csv\r\n",
      "__output__.json     __results___files  data.h5\t   prev_month_benchmark.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import gc\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "DATA_PATH = '../input/pfs-dataprep/data.h5'\n",
    "# Number of rows for tuning and training\n",
    "TRAIN_ROWS = 3000000 # (~10 months)\n",
    "# Months to reserve for ensembling methods\n",
    "META_MONTHS = 4\n",
    "\n",
    "EXCL_COLS = ['item_cnt_month']\n",
    "FIXED_PARAMS = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.1,\n",
    "    'random_state': SEED,\n",
    "    'eval_metric': 'RMSE',\n",
    "    'od_type': 'Iter', \n",
    "    'od_wait': 30\n",
    "}\n",
    "# Always treat those columns as categorical\n",
    "FIXED_CAT_COLS = ['month', 'city_id', 'type_id', 'subtype_id']\n",
    "# Choose the best combination of those columns based on the validation score\n",
    "DYNAMIC_CAT_COLS = ['shop_id', 'item_category_id', 'item_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7393103, 59)\n",
      "CPU times: user 9.94 s, sys: 4.58 s, total: 14.5 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "traintest = pd.read_hdf(DATA_PATH, key='traintest')\n",
    "\n",
    "print(traintest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000 238172 1114452\n"
     ]
    }
   ],
   "source": [
    "train_idx = traintest[traintest.date_block_num<34-META_MONTHS].sample(n=TRAIN_ROWS, random_state=SEED).index\n",
    "valid_idx = traintest[traintest.date_block_num==33].index\n",
    "test_idx = traintest[traintest.date_block_num>=34-META_MONTHS].index\n",
    "\n",
    "print(len(train_idx), len(valid_idx), len(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1114452, 58) [30, 31, 32, 33, 34]\n"
     ]
    }
   ],
   "source": [
    "X_test = traintest.loc[test_idx].drop(EXCL_COLS, axis=1)\n",
    "\n",
    "print(X_test.shape, sorted(X_test.date_block_num.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brute force categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(cat_cols):\n",
    "    start_time = time.time()\n",
    "    # Split data and build pools beforehand which takes longer if done dynamically\n",
    "    df = traintest.copy()\n",
    "    if len(cat_cols) > 0:\n",
    "        df[cat_cols] = traintest[cat_cols].astype('category', copy=False)\n",
    "        cat_features = [list(traintest.columns).index(col) for col in cat_cols]\n",
    "    else:\n",
    "        cat_features = []\n",
    "    # Split data\n",
    "    X_train = traintest.loc[train_idx].drop(EXCL_COLS, axis=1)\n",
    "    y_train = traintest.loc[train_idx].item_cnt_month\n",
    "    train_pool = Pool(data=X_train, label=y_train, cat_features=cat_features)\n",
    "    \n",
    "    X_valid = traintest.loc[valid_idx].drop(EXCL_COLS, axis=1)\n",
    "    y_valid = traintest.loc[valid_idx].item_cnt_month\n",
    "    valid_pool = Pool(data=X_valid, label=y_valid, cat_features=cat_features)\n",
    "    \n",
    "    test_pool = Pool(data=X_test, cat_features=cat_features)\n",
    "    \n",
    "    return train_pool, valid_pool, test_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_and_fit_model(train_pool, valid_pool, silent=True):\n",
    "    catboost = CatBoostRegressor(**FIXED_PARAMS)\n",
    "    catboost.fit(train_pool, silent=silent, eval_set=valid_pool, use_best_model=True)\n",
    "    train_score = catboost.best_score_['learn']['RMSE']\n",
    "    valid_score = catboost.best_score_['validation_0']['RMSE']\n",
    "    print(\"train_score {:.4f}, valid_score {:.4f}\".format(train_score, valid_score))\n",
    "    return catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(catboost, train_pool):\n",
    "    feature_scores = pd.Series(catboost.get_feature_importance(data=train_pool), \n",
    "                               index=traintest.drop('item_cnt_month', axis=1).columns)\n",
    "    feature_scores = feature_scores.sort_values(ascending=False)\n",
    "    return feature_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preds(preds, fname):\n",
    "    preds = pd.Series(preds, index=test_idx)\n",
    "    preds.to_csv(fname)\n",
    "    print(preds.head())\n",
    "    print(preds.describe()[['mean', 'std', 'min', 'max']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_list_combinations(lst):\n",
    "    all_combs = []\n",
    "    for n in range(0, len(lst)+1):\n",
    "        for i, subset in enumerate(itertools.combinations(lst, n)):\n",
    "            all_combs.append(list(subset))\n",
    "    return all_combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8: none_preds.csv\n",
      "Pools built - 21.96s\n",
      "train_score 0.8958, valid_score 0.9247\n",
      "Model fitted - 603.45s\n",
      "Dataset is provided, but PredictionValuesChange feature importance don't use it, since non-empty LeafWeights in model.\n",
      "item_cnt_month_lag_1       20.922557\n",
      "item_id_sales_sum_lag_1    12.896804\n",
      "subtype_id                  9.140871\n",
      "num_pca_0                   6.866665\n",
      "item_price_lag_1            5.269512\n",
      "dtype: float64\n",
      "6278651    0.160887\n",
      "6278652    0.379191\n",
      "6278653    0.022483\n",
      "6278654    0.090597\n",
      "6278655    0.134129\n",
      "dtype: float64\n",
      "mean     0.266209\n",
      "std      0.705307\n",
      "min     -0.437275\n",
      "max     21.154886\n",
      "dtype: float64\n",
      "2/8: shop_preds.csv\n",
      "Pools built - 22.18s\n",
      "train_score 0.8907, valid_score 0.9231\n",
      "Model fitted - 812.62s\n",
      "Dataset is provided, but PredictionValuesChange feature importance don't use it, since non-empty LeafWeights in model.\n",
      "item_cnt_month_lag_1       20.263913\n",
      "item_id_sales_sum_lag_1    13.429879\n",
      "subtype_id                  8.387386\n",
      "num_pca_0                   5.729955\n",
      "shop_id_sales_sum_lag_1     4.860101\n",
      "dtype: float64\n",
      "6278651    0.176181\n",
      "6278652    0.401640\n",
      "6278653    0.028944\n",
      "6278654    0.100268\n",
      "6278655    0.084258\n",
      "dtype: float64\n",
      "mean     0.267072\n",
      "std      0.718516\n",
      "min     -0.614629\n",
      "max     22.172652\n",
      "dtype: float64\n",
      "3/8: item_category_preds.csv\n",
      "Pools built - 22.14s\n",
      "train_score 0.8910, valid_score 0.9240\n",
      "Model fitted - 887.96s\n",
      "Dataset is provided, but PredictionValuesChange feature importance don't use it, since non-empty LeafWeights in model.\n",
      "item_cnt_month_lag_1       19.532261\n",
      "item_id_sales_sum_lag_1    13.363883\n",
      "subtype_id                  8.199031\n",
      "num_pca_0                   6.725111\n",
      "shop_id_sales_sum_lag_1     4.731881\n",
      "dtype: float64\n",
      "6278651    0.142793\n",
      "6278652    0.343990\n",
      "6278653    0.023577\n",
      "6278654    0.094561\n",
      "6278655    0.147702\n",
      "dtype: float64\n",
      "mean     0.265443\n",
      "std      0.709473\n",
      "min     -0.622274\n",
      "max     21.754761\n",
      "dtype: float64\n",
      "4/8: item_preds.csv\n",
      "Pools built - 22.98s\n",
      "train_score 0.8951, valid_score 0.9124\n",
      "Model fitted - 537.63s\n",
      "Dataset is provided, but PredictionValuesChange feature importance don't use it, since non-empty LeafWeights in model.\n",
      "item_cnt_month_lag_1       21.317877\n",
      "item_id_sales_sum_lag_1    14.632323\n",
      "subtype_id                  9.895229\n",
      "shop_id                     9.230576\n",
      "num_pca_0                   7.281533\n",
      "dtype: float64\n",
      "6278651    0.137196\n",
      "6278652    0.369024\n",
      "6278653    0.017470\n",
      "6278654    0.093973\n",
      "6278655    0.179090\n",
      "dtype: float64\n",
      "mean     0.268369\n",
      "std      0.718721\n",
      "min     -0.594062\n",
      "max     22.057767\n",
      "dtype: float64\n",
      "5/8: shop-item_category_preds.csv\n",
      "Pools built - 23.53s\n",
      "train_score 0.8925, valid_score 0.9317\n",
      "Model fitted - 806.21s\n",
      "Dataset is provided, but PredictionValuesChange feature importance don't use it, since non-empty LeafWeights in model.\n",
      "item_cnt_month_lag_1       20.959988\n",
      "item_id_sales_sum_lag_1    13.200018\n",
      "subtype_id                  8.407263\n",
      "num_pca_0                   7.327395\n",
      "item_price_lag_1            5.266689\n",
      "dtype: float64\n",
      "6278651    0.176760\n",
      "6278652    0.273004\n",
      "6278653    0.017419\n",
      "6278654    0.083553\n",
      "6278655    0.102146\n",
      "dtype: float64\n",
      "mean     0.272898\n",
      "std      0.722108\n",
      "min     -0.429552\n",
      "max     21.857135\n",
      "dtype: float64\n",
      "6/8: shop-item_preds.csv\n",
      "Pools built - 23.67s\n",
      "train_score 0.8979, valid_score 0.9197\n",
      "Model fitted - 531.31s\n",
      "Dataset is provided, but PredictionValuesChange feature importance don't use it, since non-empty LeafWeights in model.\n",
      "item_cnt_month_lag_1       21.983592\n",
      "item_id_sales_sum_lag_1    14.359239\n",
      "shop_id                     8.925121\n",
      "item_category_id            7.755336\n",
      "num_pca_0                   6.765732\n",
      "dtype: float64\n",
      "6278651    0.150706\n",
      "6278652    0.292265\n",
      "6278653    0.025549\n",
      "6278654    0.100586\n",
      "6278655    0.158394\n",
      "dtype: float64\n",
      "mean     0.271426\n",
      "std      0.717345\n",
      "min     -0.242502\n",
      "max     21.731817\n",
      "dtype: float64\n",
      "7/8: item_category-item_preds.csv\n",
      "Pools built - 23.22s\n",
      "train_score 0.9048, valid_score 0.9196\n",
      "Model fitted - 431.82s\n",
      "Dataset is provided, but PredictionValuesChange feature importance don't use it, since non-empty LeafWeights in model.\n",
      "item_cnt_month_lag_1       21.878396\n",
      "item_id_sales_sum_lag_1    14.714501\n",
      "shop_id                     9.192845\n",
      "subtype_id                  8.949575\n",
      "num_pca_0                   6.944535\n",
      "dtype: float64\n",
      "6278651    0.131062\n",
      "6278652    0.294997\n",
      "6278653    0.013905\n",
      "6278654    0.063593\n",
      "6278655    0.139912\n",
      "dtype: float64\n",
      "mean     0.267842\n",
      "std      0.706406\n",
      "min     -0.179604\n",
      "max     22.571228\n",
      "dtype: float64\n",
      "8/8: shop-item_category-item_preds.csv\n",
      "Pools built - 24.53s\n",
      "train_score 0.8935, valid_score 0.9254\n",
      "Model fitted - 697.77s\n",
      "Dataset is provided, but PredictionValuesChange feature importance don't use it, since non-empty LeafWeights in model.\n",
      "item_cnt_month_lag_1       20.062054\n",
      "item_id_sales_sum_lag_1    14.466818\n",
      "item_category_id            8.990833\n",
      "shop_id                     8.779417\n",
      "num_pca_0                   6.676113\n",
      "dtype: float64\n",
      "6278651    0.159048\n",
      "6278652    0.355123\n",
      "6278653    0.043163\n",
      "6278654    0.100442\n",
      "6278655    0.125062\n",
      "dtype: float64\n",
      "mean     0.279187\n",
      "std      0.741146\n",
      "min     -0.513904\n",
      "max     22.470690\n",
      "dtype: float64\n",
      "CPU times: user 5h 5min 30s, sys: 15min 39s, total: 5h 21min 10s\n",
      "Wall time: 1h 29min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Try all possible combinations of categorical columns and feed them to CatBoost\n",
    "all_combs = all_list_combinations(DYNAMIC_CAT_COLS)\n",
    "\n",
    "for i, subset in enumerate(all_combs):\n",
    "    # Choose a name for the file\n",
    "    join_name = '-'.join([s[:-3] for s in subset])\n",
    "    join_name = join_name if len(join_name) > 0 else 'none'\n",
    "    config_name = \"{}_preds.csv\".format(join_name)\n",
    "    print(f\"{i+1}/{len(all_combs)}: {config_name}\")\n",
    "    \n",
    "    # split data and create pool objects\n",
    "    start_time = time.time()\n",
    "    train_pool, valid_pool, test_pool = split_data(subset + FIXED_CAT_COLS)\n",
    "    print(\"Pools built - {:.2f}s\".format(time.time() - start_time))\n",
    "    \n",
    "    # fit regressor\n",
    "    catboost = setup_and_fit_model(train_pool, valid_pool)\n",
    "    print(\"Model fitted - {:.2f}s\".format(time.time() - start_time))\n",
    "    \n",
    "    # show the most important features\n",
    "    print(get_feature_importance(catboost, train_pool).head())\n",
    "    \n",
    "    # submit predictions\n",
    "    preds = catboost.predict(test_pool)\n",
    "    save_preds(preds, config_name)\n",
    "    \n",
    "    # force the Garbage Collector to release unreferenced memory\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
