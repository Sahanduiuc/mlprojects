{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/competitive-data-science-predict-future-sales:\r\n",
      "item_categories.csv  sales_train.csv\t    shops.csv\r\n",
      "items.csv\t     sample_submission.csv  test.csv\r\n",
      "\r\n",
      "../input/pfs-catboost:\r\n",
      "__notebook__.ipynb\t      item_preds.csv\r\n",
      "__output__.json\t\t      none_preds.csv\r\n",
      "__results__.html\t      shop-item_category-item_preds.csv\r\n",
      "catboost_info\t\t      shop-item_category_preds.csv\r\n",
      "custom.css\t\t      shop-item_preds.csv\r\n",
      "item_category-item_preds.csv  shop_preds.csv\r\n",
      "item_category_preds.csv\r\n",
      "\r\n",
      "../input/pfs-dataprep:\r\n",
      "__notebook__.ipynb  __results__.html   custom.css  mean_benchmark.csv\r\n",
      "__output__.json     __results___files  data.h5\t   prev_month_benchmark.csv\r\n",
      "\r\n",
      "../input/pfs-lightgbm:\r\n",
      "__notebook__.ipynb  baseline_preds.csv\t    tuned_seed_bagging_preds.csv\r\n",
      "__output__.json     custom.css\t\t    tuned_trial_bagging_preds.csv\r\n",
      "__results__.html    seed_bagging_preds.csv\r\n",
      "__results___files   tuned_preds.csv\r\n",
      "\r\n",
      "../input/pfs-linreg:\r\n",
      "__notebook__.ipynb  __results__.html   custom.css\r\n",
      "__output__.json     __results___files  vw_preds.csv\r\n",
      "\r\n",
      "../input/pfs-nn:\r\n",
      "__notebook__.ipynb  __results___files\t    custom.css\r\n",
      "__output__.json     bin_preds.csv\t    reg_preds.csv\r\n",
      "__results__.html    bin_weighted_preds.csv  sigmoid_preds.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from math import sqrt\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, validation_curve\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "from fastai import tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "DATA_PATH = '../input/pfs-dataprep/data.h5'\n",
    "TEMP_PATH = Path('temp')\n",
    "BASE_DIRS = ['../input/pfs-lightgbm', '../input/pfs-catboost', '../input/pfs-linreg', '../input/pfs-nn']\n",
    "EXCL_COLS = []\n",
    "BATCH_SIZE = 256\n",
    "FIT_ARGS = (1, 1e-2)\n",
    "FIT_KWARGS = {\n",
    "    'wd': 0.2\n",
    "}\n",
    "# Meta-models are usually simpler than base models\n",
    "NN_PARAMS = {\n",
    "    'layers': [50, 20], \n",
    "    'ps': [0.2, 0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7393103, 59)\n",
      "CPU times: user 12.3 s, sys: 11.9 s, total: 24.2 s\n",
      "Wall time: 24.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "traintest = pd.read_hdf(DATA_PATH, key='traintest')\n",
    "\n",
    "print(traintest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1114452, 18)\n",
      "CPU times: user 32.1 s, sys: 1.34 s, total: 33.4 s\n",
      "Wall time: 33.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_preds = pd.DataFrame({fpath.parents[0].stem[4:]+'_'+fpath.stem[:-6]: pd.Series.from_csv(fpath) \n",
    "                           for base_dir in BASE_DIRS\n",
    "                           for fpath in Path(base_dir).glob('*_preds.csv')})\n",
    "base_preds_cols = base_preds.columns\n",
    "\n",
    "print(base_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(traintest.columns[traintest.columns.str.contains('pca')]) + ['date_block_num', 'item_cnt_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1114452, 30)\n"
     ]
    }
   ],
   "source": [
    "data = traintest.loc[base_preds.index, cols].merge(base_preds, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    # Clipping required by the competition\n",
    "    y_true = np.clip(y_true, 0, 20)\n",
    "    y_pred = np.clip(y_pred, 0, 20)\n",
    "    return sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "rmse_scoring = make_scorer(rmse, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      corr           r2       rmse\n",
      "item_cnt_month                    1.000000     1.000000   0.000000\n",
      "lightgbm_tuned_trial_bagging      0.577723     0.311322   0.816117\n",
      "lightgbm_tuned_seed_bagging       0.586693     0.303778   0.820436\n",
      "lightgbm_seed_bagging             0.577826     0.300427   0.822661\n",
      "lightgbm_baseline                 0.575957     0.296173   0.825103\n",
      "lightgbm_tuned                    0.579606     0.291631   0.827279\n",
      "catboost_item_category            0.556358     0.279770   0.834416\n",
      "catboost_item                     0.558809     0.279852   0.834425\n",
      "catboost_none                     0.554672     0.278651   0.835214\n",
      "catboost_item_category-item       0.553222     0.276031   0.836559\n",
      "catboost_shop-item                0.554308     0.273424   0.838194\n",
      "catboost_shop-item_category       0.553042     0.269674   0.840360\n",
      "catboost_shop                     0.549713     0.266774   0.841943\n",
      "catboost_shop-item_category-item  0.553776     0.262611   0.844297\n",
      "linreg_vw                         0.506384     0.228228   0.864101\n",
      "nn_sigmoid                        0.529363     0.151779   0.905888\n",
      "nn_bin                            0.418494     0.119983   0.922711\n",
      "nn_reg                            0.512873     0.059162   0.932416\n",
      "nn_bin_weighted                   0.271928     0.016407   0.975501\n",
      "num_pca_2                         0.214343    -4.964890   0.982922\n",
      "cat_pca_3                         0.071720    -0.043341   1.004693\n",
      "cat_pca_4                         0.006766    -0.045657   1.005808\n",
      "cat_pca_0                        -0.014348    -0.046101   1.006021\n",
      "cat_pca_1                        -0.036238    -0.046364   1.006147\n",
      "cat_pca_2                        -0.020329    -0.046786   1.006350\n",
      "num_pca_4                        -0.015572    -1.437606   1.203746\n",
      "num_pca_3                         0.138135    -2.170639   1.435162\n",
      "num_pca_0                         0.168846    -5.113898   1.490562\n",
      "num_pca_1                         0.370915    -3.091089   1.838189\n",
      "date_block_num                   -0.075947 -1046.146928  19.808747\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame({\n",
    "    'corr': data.corrwith(data['item_cnt_month']).sort_values(ascending=False),\n",
    "    'r2': data.apply(lambda x: r2_score(data['item_cnt_month'], x), axis=0),\n",
    "    'rmse': data.apply(lambda x: rmse(data['item_cnt_month'], x), axis=0)\n",
    "}).sort_values(by='rmse'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(EXCL_COLS, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900252, 29) (214200, 29)\n"
     ]
    }
   ],
   "source": [
    "# Unlink data from original dataframes to clean up RAM\n",
    "# Shuffle training dataset\n",
    "train = data[data.date_block_num<34].sample(frac=1, random_state=SEED).copy()\n",
    "test = data[data.date_block_num==34].copy()\n",
    "X_train = train.drop(['item_cnt_month'], axis=1)\n",
    "y_train = train.item_cnt_month\n",
    "X_test = test.drop(['item_cnt_month'], axis=1)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del traintest\n",
    "del base_preds\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom TimeSeriesSplit-alike CV scheme using date blocks instead of timestamps\n",
    "def split_by_date_block(df):\n",
    "    df = df.reset_index()\n",
    "    # Last n months as validation blocks\n",
    "    valid_block_nums = sorted(df.date_block_num.unique())[1:]\n",
    "    time_split = []\n",
    "    for valid_block_num in valid_block_nums:\n",
    "        train_idxs = df[df.date_block_num < valid_block_num].index\n",
    "        valid_idxs = df[df.date_block_num == valid_block_num].index\n",
    "        print(valid_block_num, len(train_idxs), len(valid_idxs))\n",
    "        time_split.append((train_idxs, valid_idxs))\n",
    "    return time_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 228889 214536\n",
      "32 443425 218655\n",
      "33 662080 238172\n"
     ]
    }
   ],
   "source": [
    "block_split = split_by_date_block(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(model):\n",
    "    return np.abs(cross_val_score(model, X_train, y_train, cv=block_split, scoring=rmse_scoring, n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.756481 0.869849 0.891928]\n",
      "[0.756488 0.869848 0.891899]\n",
      "[1.06302  1.154245 1.136213]\n",
      "[0.988856 1.091881 1.080974]\n"
     ]
    }
   ],
   "source": [
    "print(cross_validate(LinearRegression()))\n",
    "print(cross_validate(Ridge(random_state=SEED)))\n",
    "print(cross_validate(Lasso(random_state=SEED)))\n",
    "print(cross_validate(ElasticNet(random_state=SEED)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=42, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = Ridge(random_state=SEED)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lightgbm_tuned_seed_bagging         0.476372\n",
       "lightgbm_baseline                   0.390427\n",
       "cat_pca_2                           0.387303\n",
       "nn_bin                              0.344304\n",
       "catboost_item_category              0.334648\n",
       "catboost_item                       0.301433\n",
       "lightgbm_tuned                      0.252630\n",
       "lightgbm_tuned_trial_bagging        0.245174\n",
       "catboost_shop-item_category-item    0.043903\n",
       "nn_sigmoid                          0.041288\n",
       "catboost_shop-item_category         0.034666\n",
       "num_pca_2                           0.022826\n",
       "num_pca_0                           0.019902\n",
       "nn_reg                              0.014434\n",
       "num_pca_3                           0.006136\n",
       "date_block_num                      0.001123\n",
       "num_pca_1                           0.000029\n",
       "num_pca_4                          -0.009087\n",
       "linreg_vw                          -0.054901\n",
       "catboost_item_category-item        -0.084929\n",
       "catboost_shop-item                 -0.110520\n",
       "nn_bin_weighted                    -0.112905\n",
       "catboost_none                      -0.190283\n",
       "catboost_shop                      -0.225103\n",
       "cat_pca_1                          -0.330170\n",
       "lightgbm_seed_bagging              -0.559833\n",
       "cat_pca_3                          -0.581439\n",
       "cat_pca_4                          -0.699259\n",
       "cat_pca_0                          -1.476521\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature importance\n",
    "pd.Series(lr.coef_, index=X_train.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214200,)\n"
     ]
    }
   ],
   "source": [
    "lr_preds = lr.predict(X_test)\n",
    "\n",
    "print(lr_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "LIST_ARGS = {\n",
    "    'path': TEMP_PATH,\n",
    "    'cont_names': train.columns.difference(['item_cnt_month'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed():\n",
    "    # This snippet gives repeatable results\n",
    "    np.random.seed(SEED)\n",
    "    tabular.torch.manual_seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    if tabular.torch.cuda.is_available(): \n",
    "        tabular.torch.cuda.manual_seed(SEED)\n",
    "        tabular.torch.cuda.manual_seed_all(SEED)\n",
    "        tabular.torch.backends.cudnn.deterministic = True\n",
    "        tabular.torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_and_fit_nn(data, use_sigmoid=False):\n",
    "    # Setup and fit NN using provided fastai data loaders\n",
    "    set_random_seed()\n",
    "    if use_sigmoid:\n",
    "        y_range = tabular.torch.tensor([0, 20], device=tabular.defaults.device)\n",
    "        learn = tabular.tabular_learner(data, **NN_PARAMS, y_range=y_range)\n",
    "    else:\n",
    "        learn = tabular.tabular_learner(data, **NN_PARAMS)\n",
    "    learn.fit_one_cycle(*FIT_ARGS, **FIT_KWARGS)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_nn(use_sigmoid=False):\n",
    "    # Cross validate NN\n",
    "    # Tried https://github.com/skorch-dev/skorch but got errors while importing the lib\n",
    "    valid_scores = []\n",
    "    for train_idx, valid_idx in block_split:\n",
    "        train_set = train.iloc[train_idx]\n",
    "        valid_set = train.iloc[valid_idx]\n",
    "        valid_data = tabular.TabularList.from_df(valid_set, **LIST_ARGS)\n",
    "        train_data = (tabular.TabularList.from_df(train_set, **LIST_ARGS)\n",
    "                      .split_none()\n",
    "                      .label_from_df('item_cnt_month', label_cls=tabular.FloatList)\n",
    "                      .add_test(valid_data)\n",
    "                      .databunch(bs=BATCH_SIZE))\n",
    "        learn = setup_and_fit_nn(train_data, use_sigmoid=use_sigmoid)\n",
    "        valid_preds = learn.get_preds(tabular.DatasetType.Test)\n",
    "        valid_score = rmse(valid_set['item_cnt_month'], valid_preds[0].squeeze())\n",
    "        valid_scores.append(valid_score)\n",
    "    return np.array(valid_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.151894, 0.863121, 0.884979])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate_nn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.740632,  0.897649,  0.89988 ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate_nn(use_sigmoid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = tabular.TabularList.from_df(test, **LIST_ARGS)\n",
    "train_data = (tabular.TabularList.from_df(train, **LIST_ARGS)\n",
    "              .split_none()\n",
    "              .label_from_df('item_cnt_month', label_cls=tabular.FloatList)\n",
    "              .add_test(test_data)\n",
    "              .databunch(bs=BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.714119</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = setup_and_fit_nn(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214200,)\n"
     ]
    }
   ],
   "source": [
    "nn_preds = learn.get_preds(tabular.DatasetType.Test)\n",
    "nn_preds = nn_preds[0].data.numpy().T[0]\n",
    "\n",
    "print(nn_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some tweaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_target_dist(preds, target):\n",
    "    # Transfer target distribution to predictions by using their ranking\n",
    "    norm_dist = pd.Series(target).value_counts(normalize=True).sort_index()\n",
    "    preds_sr = pd.Series(preds).sort_values()\n",
    "    left_idx = 0\n",
    "    for i, (value, norm_count) in enumerate(norm_dist.items()):\n",
    "        if i == len(norm_dist)-1:\n",
    "            right_idx = len(preds_sr)\n",
    "        else:\n",
    "            right_idx = left_idx + max(math.floor(norm_count * len(preds_sr)), 1)\n",
    "        preds_sr[left_idx:right_idx] = value\n",
    "        left_idx = right_idx\n",
    "    return preds_sr.sort_index().values\n",
    "\n",
    "class RankingTransformer(TransformerMixin):\n",
    "    # Sort data and apply target distribution to mimic it\n",
    "    def __init__(self): \n",
    "        pass\n",
    "    \n",
    "    def transform(self, X): \n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return X.apply(lambda x: apply_target_dist(x, self.y), axis=0)\n",
    "        else:\n",
    "            return apply_target_dist(X, self.y)\n",
    "    \n",
    "    def fit(self, y): \n",
    "        self.y = y; \n",
    "        return self\n",
    "    \n",
    "    def fit_transform(self, X, y): \n",
    "        return self.fit(y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214200,)\n"
     ]
    }
   ],
   "source": [
    "# We can try to treat our predictions as ranks for true target distribution\n",
    "# Knowing that 85% of labels are zero, we can set lowest 85% predictions as zero\n",
    "tweak1_preds = RankingTransformer().fit_transform(lr_preds, y_train)\n",
    "\n",
    "print(tweak1_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214200,)\n"
     ]
    }
   ],
   "source": [
    "# We can also convert base-model predictions to ranks, apply target distribution, and average\n",
    "tweak2_preds = RankingTransformer().fit_transform(X_test[base_preds_cols], y_train).mean(axis=1).values\n",
    "\n",
    "print(tweak2_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(preds, fname):\n",
    "    submission = pd.DataFrame({\"item_cnt_month\": preds})\n",
    "    submission['ID'] = range(len(preds))\n",
    "    submission['item_cnt_month'] = submission.item_cnt_month.clip(0, 20)\n",
    "    submission.to_csv(fname, index=False)\n",
    "    print(submission.head())\n",
    "    print(submission.item_cnt_month.describe()[['mean', 'std', 'min', 'max']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   item_cnt_month  ID\n",
      "0        0.432425   0\n",
      "1        0.313191   1\n",
      "2        1.066025   2\n",
      "3        0.361724   3\n",
      "4        2.540140   4\n",
      "mean     0.305499\n",
      "std      0.795801\n",
      "min      0.000000\n",
      "max     20.000000\n",
      "Name: item_cnt_month, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "submit(lr_preds, 'lr_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   item_cnt_month  ID\n",
      "0        0.487601   0\n",
      "1        0.368858   1\n",
      "2        1.012811   2\n",
      "3        0.353027   3\n",
      "4        2.181544   4\n",
      "mean     0.315731\n",
      "std      0.737215\n",
      "min      0.000000\n",
      "max     18.507410\n",
      "Name: item_cnt_month, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "submit(nn_preds, 'nn_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   item_cnt_month  ID\n",
      "0             0.0   0\n",
      "1             0.0   1\n",
      "2             1.0   2\n",
      "3             0.0   3\n",
      "4             3.0   4\n",
      "mean     0.267418\n",
      "std      1.093086\n",
      "min      0.000000\n",
      "max     20.000000\n",
      "Name: item_cnt_month, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "submit(tweak1_preds, 'tweak1_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   item_cnt_month  ID\n",
      "0        0.611111   0\n",
      "1        0.055556   1\n",
      "2        1.055556   2\n",
      "3        0.000000   3\n",
      "4        3.444444   4\n",
      "mean     0.267418\n",
      "std      1.015246\n",
      "min      0.000000\n",
      "max     20.000000\n",
      "Name: item_cnt_month, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "submit(tweak2_preds, 'tweak2_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
