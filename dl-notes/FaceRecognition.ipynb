{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Facial recognition is a biometric solution that measures unique characteristics about one’s face\n",
    "\n",
    "<img width=400 src=\"images/t01a5ed8aab97b460c9.jpg\"/>\n",
    "<center><a href=\"https://hackernoon.com/building-a-facial-recognition-pipeline-with-deep-learning-in-tensorflow-66e7645015b8\" style=\"color: lightgrey\">Credit</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verification vs. recognition:\n",
    "- Face verification is concerned with validating a claimed identity based on the image of a face, and either accepting or rejecting the identity claim (one-to-one matching)\n",
    "- The goal of face identification is to identify a person based on the image of a face (one-to-many matching)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difficulties:\n",
    "- We cannot use plain classification for face recognition for two reasons: \n",
    "    1. CNN doesn’t work on a small training sets, since a vanilla cross-entropy-loss softmax classifier severely overfits to the limited data,\n",
    "    2. It is not convenient to retrain the model every time we add a picture of a new person to the system.\n",
    "- Also, we cannot use similarity functions like L2 distance, which suffer from the ominous sounding curse of dimensionality and so won’t work well for data with thousands of dimensions.\n",
    "- But we can use a deep convolutional network to learn some kind of similarity function that a classifer like nearest neighbor can use to classify a face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-shot learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One-shot learning is an object categorization problem in computer vision, which aims to learn information about object categories from one, or only a few, training images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Siamese network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Siamese NNs are popular among tasks that involve finding similarity or a relationship between two comparable things. Instead of a model learning to classify its inputs, the neural networks learns to differentiate between two inputs. It learns the similarity between them.\n",
    "- Siamese seem best suited for cases where we can have only a few examples per class.\n",
    "\n",
    "<img width=300 src=\"images/Futurama.png\"/>\n",
    "<center><a href=\"https://sorenbouma.github.io/blog/oneshot/\" style=\"color: lightgrey\">Credit</a></center>\n",
    "\n",
    "- Siamese neural network is a class of neural network architectures that contain two or more identical subnetworks. identical here means they have the same configuration with the same parameters and weights. \n",
    "- Parameter updating is mirrored across both subnetworks.\n",
    "- The last layers of the two networks are fed to a loss function, which calculates the similarity between the embeddings. \n",
    "- You can also learn the similarity function by letting the network adjust the weights and biases of the logistic regression.\n",
    "\n",
    "<img width=600 src=\"images/Siamese-network.jpg\"/>\n",
    "<center><a href=\"https://www.researchgate.net/publication/328376369_Partial_Discharge_Recognition_with_a_Multi-Resolution_Convolutional_Neural_Network\" style=\"color: lightgrey\">Credit</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embeddings:\n",
    "- Embedding is projecting input features to a some higher-dimensional space\n",
    "- It means converting data to a feature representation where certain properties can be represented by notions of distance (such as semantic similarity)\n",
    "- In the embedding space, similar features should be close together and form well-separated clusters.\n",
    "- Furthermore, an SVM classifier or any other simple multi-class classifier can be trained to cluster vector embeddings effectively\n",
    "\n",
    "<img width=350 src=\"images/olivetti_tsne.jpg\"/>\n",
    "<center><a href=\"https://lvdmaaten.github.io/tsne/\" style=\"color: lightgrey\">Credit</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pros:\n",
    "- Sharing weights across subnetworks means fewer parameters to train for, which in turn means less data required and less tendency to overfit.\n",
    "- Robustness to class imbalance: If the model has learnt well what makes any classes the same, one example of an another class in training may be sufficient to predict this class in the future.\n",
    "- Ensembling with best classifier: Given that its learning mechanism is somewhat different from classification, simple averaging of it with a classifier can do much better than averaging two correlated supervised models.\n",
    "- Better embeddings. Siamese focus on learning embeddings (in deeper layer) that place same classes close together. Hence, it can learn semantic similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cons:\n",
    "- Training involves pairwise learning and thus slower than classification (pointwise learning)\n",
    "- Prediction can be slightly slower. It does not readily output class probabilities, but distances from each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contrastive loss:\n",
    "- Takes a pair of images and trains the embeddings so that the distance between them is minimized if they're from the same class and is greater than some margin value if they represent different classes.\n",
    "- Intuitively, this function just evaluates how well the network is distinguishing a given pair of images.\n",
    "\n",
    "<img width=600 src=\"images/1*tzGB6D97tHWR_-NJ8FKknw.jpeg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Triplet loss:\n",
    "- Triplet Loss is one of the loss functions we can use to solve the similarity distance in a Siamese network.\n",
    "- The goal of the triplet loss is to make sure that two examples with the same label have their embeddings close together in the embedding space, while two examples with different labels have their embeddings far away.\n",
    "- Each training sample is actually composed of a “triplet” of examples: anchor ($A$), a positive of the same class as the anchor ($P$), and a negative of a different class ($N$).\n",
    "- The contrastive loss, on the other hand, only considers pairwise examples at a time.\n",
    "\n",
    "<img width=550 src=\"images/main-qimg-e09a3ebbb08ee14ef4301170fe6649c8.png\"/>\n",
    "<center><a href=\"https://arxiv.org/pdf/1503.03832v3.pdf\" style=\"color: lightgrey\">Credit</a></center>\n",
    "\n",
    "- Implementation:\n",
    "    - Encode triplets as embeddings in some vector space\n",
    "    - Calculate the two distances $d(A,P)$ and $d(A,N)$ in the embedding space\n",
    "    - Define margin so that minimizing the loss both pushes $d(A,P)$ to zero, and $d(A,N)$ to be bigger than $d(A,P)+margin$. This is very similar to the margin used in SVMs. Having a margin indicates that dissimilar pairs that are beyond this margin will not contribute to the loss.\n",
    "    \n",
    "<img width=700 src=\"images/1*VDOSM4zQMQxMkUBezWAkiw.png\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Requires training with multiple images of the same face\n",
    "- If we choose them randomly, it will be so easy to satisfy the constraint of the loss function because the distance is going to be most of the time so large. We need to find $A$, $P$, and $N$ so that $A$ and $P$ are close to $N$. Our objective is to make it harder to train the model to push the gradient descent to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary classification:\n",
    "- Binary classification is another way to learn the similarity function, e.g., using Manhattan distance and sigmoid layer\n",
    "\n",
    "<img width=900 src=\"images/Siamese_diagram_2.png\"/>\n",
    "<center><a href=\"https://sorenbouma.github.io/blog/oneshot/\" style=\"color: lightgrey\">Credit</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Siamese Neural Networks for One-shot Image Recognition (2015)](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf)\n",
    "- [Triplet Loss and Online Triplet Mining in TensorFlow](https://omoindrot.github.io/triplet-loss)\n",
    "- [Siamese and triplet learning with online pair/triplet mining](https://github.com/adambielski/siamese-triplet)\n",
    "- [One Shot Learning and Siamese Networks in Keras](https://sorenbouma.github.io/blog/oneshot/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FaceNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FaceNet is the backbone of many open source face recognition system like OpenFace\n",
    "- FaceNet uses Siamese network to transform a face into 128D Euclidian space similar to word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [DeepFace: Closing the Gap to Human-Level Performance in Face Verification (2014)](https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf)\n",
    "- [FaceNet: A Unified Embedding for Face Recognition and Clustering (2015)](https://arxiv.org/pdf/1503.03832.pdf)\n",
    "- [Deep Face Recognition (2015)](http://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
