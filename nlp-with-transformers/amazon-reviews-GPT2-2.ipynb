{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/olegpolakow/miniconda3/lib/python3.7/site-packages (2.1.1)\n",
      "Requirement already satisfied: tqdm in /Users/olegpolakow/miniconda3/lib/python3.7/site-packages (from transformers) (4.32.1)\n",
      "Requirement already satisfied: regex in /Users/olegpolakow/miniconda3/lib/python3.7/site-packages (from transformers) (2019.8.19)\n",
      "Requirement already satisfied: requests in /Users/olegpolakow/miniconda3/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: boto3 in /Users/olegpolakow/miniconda3/lib/python3.7/site-packages (from transformers) (1.9.205)\n",
      "Requirement already satisfied: sentencepiece in /Users/olegpolakow/miniconda3/lib/python3.7/site-packages (from transformers) (0.1.83)\n",
      "Requirement already satisfied: sacremoses in /Users/olegpolakow/miniconda3/lib/python3.7/site-packages (from transformers) (0.0.35)\n",
      "Requirement already satisfied: numpy in /Users/olegpolakow/miniconda3/lib/python3.7/site-packages (from transformers) (1.17.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/olegpolakow/miniconda3/lib/python3.7/site-packages (from requests->transformers) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/olegpolakow/miniconda3/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/olegpolakow/miniconda3/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/olegpolakow/miniconda3/lib/python3.7/site-packages (from requests->transformers) (2019.6.16)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/olegpolakow/.local/lib/python3.7/site-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.205 in /Users/olegpolakow/.local/lib/python3.7/site-packages (from boto3->transformers) (1.12.205)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /Users/olegpolakow/.local/lib/python3.7/site-packages (from boto3->transformers) (0.2.1)\n",
      "Requirement already satisfied: click in /Users/olegpolakow/miniconda3/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: six in /Users/olegpolakow/miniconda3/lib/python3.7/site-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: joblib in /Users/olegpolakow/miniconda3/lib/python3.7/site-packages (from sacremoses->transformers) (0.13.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /Users/olegpolakow/.local/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.205->boto3->transformers) (2.8.0)\n",
      "Requirement already satisfied: docutils<0.15,>=0.10 in /Users/olegpolakow/.local/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.205->boto3->transformers) (0.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path('data')\n",
    "IN_PATH = DATA_DIR/'amazon-reviews-balanced.csv'\n",
    "OUT_PATH = DATA_DIR/'amazon-reviews-sample.txt'\n",
    "SEED = 42\n",
    "SAMPLE_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1067020\n"
     ]
    }
   ],
   "source": [
    "def count_lines(path):\n",
    "    \"\"\"Count the number of lines in a file.\"\"\"\n",
    "    with open(path, 'r', encoding='utf8', errors='ignore') as f:\n",
    "        return sum(1 for line in f)\n",
    "    \n",
    "lines_count = count_lines(IN_PATH)\n",
    "\n",
    "print(lines_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [40961, 806915, 28677, 233478, 227336]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "def random_sample(arr, sample_size, seed):\n",
    "    \"\"\"Sample randomly from an array.\"\"\"\n",
    "    random.seed(seed)\n",
    "    if sample_size <= 1:\n",
    "        sample_size = math.floor(sample_size * len(arr))\n",
    "    idx_sample = set(random.sample(arr, sample_size))\n",
    "    return idx_sample\n",
    "\n",
    "idx_sample = random_sample(range(lines_count), SAMPLE_SIZE, SEED)\n",
    "\n",
    "print(len(idx_sample), list(idx_sample)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e75e5e8b6944ea59a9a92c29ab06453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def preprocess_data(in_path, out_path, idx_sample):\n",
    "    \"\"\"For each line in input, preprocess it for the use in GPT-2, and append to output.\"\"\"\n",
    "    if out_path.exists():\n",
    "        # Remove target if exists (since we are in append-mode)\n",
    "        out_path.unlink()\n",
    "\n",
    "    pbar = tqdm(total=len(idx_sample))\n",
    "    with open(in_path, 'r', encoding='utf8') as inf:\n",
    "        with open(out_path, 'a', encoding='utf8') as outf:\n",
    "            reader = csv.reader(inf, delimiter=\",\")\n",
    "            for i, row in enumerate(reader):\n",
    "                if i in idx_sample:\n",
    "                    product_category, review_body, star_rating = row\n",
    "                    # Wrap product category and star rating into special symbols \n",
    "                    # for the GPT-2 model to distinguish them from the body text\n",
    "                    text = '|' + product_category.replace('_', ' ') # otherwise '_' is treated as token\n",
    "                    text += '|' + str(star_rating)\n",
    "                    text += '|' + review_body\n",
    "                    text += \"<|endoftext|>\" # use a special token to mark the end of the review\n",
    "                    text += \"\\n\" # for convenience and being able to do fp.readline() on text file\n",
    "                    outf.write(text)\n",
    "                    pbar.update()\n",
    "                    \n",
    "preprocess_data(IN_PATH, OUT_PATH, idx_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Digital Software|2|Product advertises Blu-Ray support but then after you buy it there is no Blu-Ray support.  You can however buy a $20 plugin for Blu-Ray support but that is an additional cost and the way the product description reads there is no mention the need to buy this extra plugin.<br /><br />Also there appears to be no telephone support.  If you have any issues with getting it to work or issues with anything including billing, etc. you have to go through there web page support which doesn't appear to have anyone on the other end and no one returns my inquiries.<br /><br />Product does work on the Mac however.  Not as good as Nero but only solution for the Mac.  I did buy the plugin and Blu-rays burn fine though I was billed twice for the plugin.<br /><br />I wish there was an alternative seeing as how it's so difficult to contact someone if you need support.<|endoftext|>\n",
      "\n",
      "['|', 'Digital', 'ĠSoftware', '|', '2', '|', 'Product', 'Ġadvert', 'ises', 'ĠBlu', '-', 'Ray', 'Ġsupport', 'Ġbut', 'Ġthen', 'Ġafter', 'Ġyou', 'Ġbuy', 'Ġit', 'Ġthere', 'Ġis', 'Ġno', 'ĠBlu', '-', 'Ray', 'Ġsupport', '.', 'Ġ', 'ĠYou', 'Ġcan', 'Ġhowever', 'Ġbuy', 'Ġa', 'Ġ$', '20', 'Ġplugin', 'Ġfor', 'ĠBlu', '-', 'Ray', 'Ġsupport', 'Ġbut', 'Ġthat', 'Ġis', 'Ġan', 'Ġadditional', 'Ġcost', 'Ġand', 'Ġthe', 'Ġway', 'Ġthe', 'Ġproduct', 'Ġdescription', 'Ġreads', 'Ġthere', 'Ġis', 'Ġno', 'Ġmention', 'Ġthe', 'Ġneed', 'Ġto', 'Ġbuy', 'Ġthis', 'Ġextra', 'Ġplugin', '.<', 'br', 'Ġ/', '><', 'br', 'Ġ/>', 'Also', 'Ġthere', 'Ġappears', 'Ġto', 'Ġbe', 'Ġno', 'Ġtelephone', 'Ġsupport', '.', 'Ġ', 'ĠIf', 'Ġyou', 'Ġhave', 'Ġany', 'Ġissues', 'Ġwith', 'Ġgetting', 'Ġit', 'Ġto', 'Ġwork', 'Ġor', 'Ġissues', 'Ġwith', 'Ġanything', 'Ġincluding', 'Ġbilling', ',', 'Ġetc', '.', 'Ġyou', 'Ġhave', 'Ġto', 'Ġgo', 'Ġthrough', 'Ġthere', 'Ġweb', 'Ġpage', 'Ġsupport', 'Ġwhich', 'Ġdoesn', \"'t\", 'Ġappear', 'Ġto', 'Ġhave', 'Ġanyone', 'Ġon', 'Ġthe', 'Ġother', 'Ġend', 'Ġand', 'Ġno', 'Ġone', 'Ġreturns', 'Ġmy', 'Ġinquiries', '.<', 'br', 'Ġ/', '><', 'br', 'Ġ/>', 'Product', 'Ġdoes', 'Ġwork', 'Ġon', 'Ġthe', 'ĠMac', 'Ġhowever', '.', 'Ġ', 'ĠNot', 'Ġas', 'Ġgood', 'Ġas', 'ĠNero', 'Ġbut', 'Ġonly', 'Ġsolution', 'Ġfor', 'Ġthe', 'ĠMac', '.', 'Ġ', 'ĠI', 'Ġdid', 'Ġbuy', 'Ġthe', 'Ġplugin', 'Ġand', 'ĠBlu', '-', 'rays', 'Ġburn', 'Ġfine', 'Ġthough', 'ĠI', 'Ġwas', 'Ġbilled', 'Ġtwice', 'Ġfor', 'Ġthe', 'Ġplugin', '.<', 'br', 'Ġ/', '><', 'br', 'Ġ/>', 'I', 'Ġwish', 'Ġthere', 'Ġwas', 'Ġan', 'Ġalternative', 'Ġseeing', 'Ġas', 'Ġhow', 'Ġit', \"'s\", 'Ġso', 'Ġdifficult', 'Ġto', 'Ġcontact', 'Ġsomeone', 'Ġif', 'Ġyou', 'Ġneed', 'Ġsupport', '.', '<|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "with open(OUT_PATH, 'r', encoding='utf8') as f:\n",
    "    row = f.readline()\n",
    "    print(row)\n",
    "    print(tokenizer.tokenize(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/olegpolakow/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/olegpolakow/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/olegpolakow/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/olegpolakow/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/olegpolakow/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/olegpolakow/miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n",
      "/Users/olegpolakow/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/olegpolakow/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/olegpolakow/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/olegpolakow/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/olegpolakow/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/olegpolakow/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:__main__:Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
      "100%|███████████████████████████████████████| 176/176 [00:00<00:00, 45976.43B/s]\n",
      "100%|█████████████████████████| 548118077/548118077 [00:57<00:00, 9476142.47B/s]\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (62644 > 1024). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "WARNING:transformers.tokenization_utils:This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "Epoch:   0%|                                              | 0/1 [00:00<?, ?it/s]\n",
      "Iteration:   0%|                                         | 0/16 [00:00<?, ?it/s]\u001b[A^C\n"
     ]
    }
   ],
   "source": [
    "!python run_lm_finetuning.py \\\n",
    "    --output_dir=output \\\n",
    "    --model_type=gpt2 \\\n",
    "    --model_name_or_path=gpt2 \\\n",
    "    --do_train \\\n",
    "    --train_data_file=$OUT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "4c486030c0554d25a4400232025eeee6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_de27354ff7934697a9e5c27455db87b1",
       "max": 1000,
       "style": "IPY_MODEL_c2eb0ac03fe44b11a9707ddd4604bc32",
       "value": 1000
      }
     },
     "4e75e5e8b6944ea59a9a92c29ab06453": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4c486030c0554d25a4400232025eeee6",
        "IPY_MODEL_e7444b385178417ca5d6c7707bb32738"
       ],
       "layout": "IPY_MODEL_7130e6896069407e948cbeee942d3060"
      }
     },
     "7130e6896069407e948cbeee942d3060": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7deda9f3d2fc4fc89398b86ac6d1ceb2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c2eb0ac03fe44b11a9707ddd4604bc32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cb9b631689a34eefa77dc92dcc1d58b2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "de27354ff7934697a9e5c27455db87b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e7444b385178417ca5d6c7707bb32738": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_cb9b631689a34eefa77dc92dcc1d58b2",
       "style": "IPY_MODEL_7deda9f3d2fc4fc89398b86ac6d1ceb2",
       "value": "100% 1000/1000 [00:03&lt;00:00, 253.07it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
